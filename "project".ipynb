{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmxoGl3WAqXZxuLieChRCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayaRedFox/DS_intro/blob/main/%22project%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1. –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï GOOGLE DRIVE –ò –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•\n",
        "# ============================================\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# –ü–æ–¥–∫–ª—é—á–∞–µ–º Google Drive\n",
        "print(\"–ü–æ–¥–∫–ª—é—á–∞–µ–º Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω!\")\n",
        "\n",
        "# –ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–æ–≤ –Ω–∞ Google Drive\n",
        "import glob\n",
        "\n",
        "# –ò—â–µ–º –≤—Å–µ CSV —Ñ–∞–π–ª—ã\n",
        "print(\"\\n–ò—â–µ–º CSV —Ñ–∞–π–ª—ã –Ω–∞ Google Drive...\")\n",
        "csv_files = glob.glob('/content/drive/MyDrive/**/*.csv', recursive=True)\n",
        "\n",
        "if csv_files:\n",
        "    print(f\"–ù–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤: {len(csv_files)}\")\n",
        "    for i, file_path in enumerate(csv_files, 1):\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        print(f\"{i}. {file_path} ({file_size} –±–∞–π—Ç)\")\n",
        "\n",
        "    # –ï—Å–ª–∏ —Ñ–∞–π–ª –æ–¥–∏–Ω - –∑–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ\n",
        "    if len(csv_files) == 1:\n",
        "        file_path = csv_files[0]\n",
        "        print(f\"\\n–ó–∞–≥—Ä—É–∂–∞–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª: {file_path}\")\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        print(f\"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!\")\n",
        "        print(f\"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "        print(f\"üìÅ –ò–º—è —Ñ–∞–π–ª–∞: {os.path.basename(file_path)}\")\n",
        "\n",
        "    else:\n",
        "        # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π\n",
        "        file_path = csv_files[0]\n",
        "        print(f\"\\n–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—ã–π CSV —Ñ–∞–π–ª: {file_path}\")\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        print(f\"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!\")\n",
        "        print(f\"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "\n",
        "else:\n",
        "    print(\"CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ Google Drive!\")\n",
        "    print(\"–ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É...\")\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É\n",
        "    root_files = os.listdir('/content/drive/MyDrive')\n",
        "    print(f\"–§–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ: {root_files}\")\n",
        "\n",
        "    # –ò—â–µ–º CSV –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ\n",
        "    for file in root_files:\n",
        "        if file.endswith('.csv'):\n",
        "            file_path = f'/content/drive/MyDrive/{file}'\n",
        "            print(f\"\\n–ù–∞–π–¥–µ–Ω CSV —Ñ–∞–π–ª: {file_path}\")\n",
        "            df = pd.read_csv(file_path)\n",
        "            print(f\"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!\")\n",
        "            break\n",
        "\n",
        "# ============================================\n",
        "# 2. –û–°–ù–û–í–ù–ê–Ø –ß–ê–°–¢–¨ –ö–û–î–ê (–∫–∞–∫ –≤ –≤–∞—à–µ–º –∑–∞–¥–∞–Ω–∏–∏)\n",
        "# ============================================\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n",
        "if 'df' in locals():\n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"üìà –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "    print(\"\\nüìã –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"\\nüìù –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–æ–Ω–∫–∞—Ö:\")\n",
        "    print(df.info())\n",
        "\n",
        "    print(\"\\nüî¢ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\")\n",
        "    print(df.describe())\n",
        "\n",
        "    print(\"\\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    print(f\"\\nüîé –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {df.duplicated().sum()}\")\n",
        "\n",
        "    # ============================================\n",
        "    # 3. –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï –ö–û–î–ê –ò–ó –í–ê–®–ï–ì–û –ó–ê–î–ê–ù–ò–Ø\n",
        "    # ============================================\n",
        "\n",
        "    import numpy as np\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib import rcParams\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "    rcParams['figure.figsize'] = (12, 8)\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "\n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏\n",
        "    pd.set_option('display.max_columns', None)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"–ù–ê–ó–í–ê–ù–ò–Ø –ö–û–õ–û–ù–û–ö –í –î–ê–¢–ê–°–ï–¢–ï:\")\n",
        "    print(\"=\"*60)\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"{i}. {col} - {df[col].dtype}\")\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
        "    expected_columns = ['gender', 'math score', 'reading score', 'writing score']\n",
        "    missing_columns = [col for col in expected_columns if col not in df.columns]\n",
        "\n",
        "    if missing_columns:\n",
        "        print(f\"\\n‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ! –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}\")\n",
        "        print(\"–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫:\")\n",
        "        print(df.columns.tolist())\n",
        "\n",
        "        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫\n",
        "        print(\"\\nüîé –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫...\")\n",
        "        for expected in expected_columns:\n",
        "            similar = [col for col in df.columns if expected.lower() in col.lower()]\n",
        "            if similar:\n",
        "                print(f\"–î–ª—è '{expected}' –Ω–∞–π–¥–µ–Ω—ã –ø–æ—Ö–æ–∂–∏–µ: {similar}\")\n",
        "    else:\n",
        "        print(\"\\n‚úÖ –í—Å–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ!\")\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π DataFrame –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "    print(\"\\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º DataFrame –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...\")\n",
        "    original_df = df.copy()\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞...\")\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ\n",
        "    np.random.seed(42)\n",
        "    n_samples = 1000\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'gender': np.random.choice(['female', 'male'], n_samples),\n",
        "        'race/ethnicity': np.random.choice(['group A', 'group B', 'group C', 'group D', 'group E'], n_samples),\n",
        "        'parental level of education': np.random.choice([\n",
        "            'some high school', 'high school', 'some college',\n",
        "            \"associate's degree\", \"bachelor's degree\", \"master's degree\"\n",
        "        ], n_samples),\n",
        "        'lunch': np.random.choice(['standard', 'free/reduced'], n_samples),\n",
        "        'test preparation course': np.random.choice(['none', 'completed'], n_samples),\n",
        "        'math score': np.random.normal(66, 15, n_samples).clip(0, 100).astype(int),\n",
        "        'reading score': np.random.normal(69, 14, n_samples).clip(0, 100).astype(int),\n",
        "        'writing score': np.random.normal(68, 15, n_samples).clip(0, 100).astype(int),\n",
        "    })\n",
        "\n",
        "    print(\"‚úÖ –°–æ–∑–¥–∞–Ω –¥–µ–º–æ-–¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\")\n",
        "    original_df = df.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "PAhF-aOVQXpk",
        "outputId": "9d80dfcc-3a1b-4a35-e1ba-7b149a50db83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–¥–∫–ª—é—á–∞–µ–º Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω!\n",
            "\n",
            "–ò—â–µ–º CSV —Ñ–∞–π–ª—ã –Ω–∞ Google Drive...\n",
            "–ù–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤: 1\n",
            "1. /content/drive/MyDrive/Colab_Data/students_data.csv (79462 –±–∞–π—Ç)\n",
            "\n",
            "–ó–∞–≥—Ä—É–∂–∞–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª: /content/drive/MyDrive/Colab_Data/students_data.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xb1 in position 11: invalid start byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-795592287.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n–ó–∞–≥—Ä—É–∂–∞–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª: {file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb1 in position 11: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# –ü–†–û–î–û–õ–ñ–ï–ù–ò–ï: FEATURE ENGINEERING\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π - —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞\n",
        "df['average_score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1).round(2)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –±–∞–ª–ª–∞\n",
        "df['total_score'] = df['math score'] + df['reading score'] + df['writing score']\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ —É—Å–ø–µ–≤–∞–µ–º–æ—Å—Ç–∏ (–≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ = 1)\n",
        "df['above_average'] = (df['average_score'] > df['average_score'].mean()).astype(int)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —É—Ä–æ–≤–Ω—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–æ–¥–∏—Ç–µ–ª–µ–π (–ø–æ—Ä—è–¥–∫–æ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)\n",
        "education_order = {\n",
        "    'some high school': 1,\n",
        "    'high school': 2,\n",
        "    'some college': 3,\n",
        "    \"associate's degree\": 4,\n",
        "    \"bachelor's degree\": 5,\n",
        "    \"master's degree\": 6\n",
        "}\n",
        "df['parent_education_level'] = df['parental level of education'].map(education_order)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –æ—Ü–µ–Ω–æ–∫\n",
        "df['score_balance'] = abs(df['math score'] - df['reading score']) + \\\n",
        "                      abs(df['math score'] - df['writing score']) + \\\n",
        "                      abs(df['reading score'] - df['writing score'])\n",
        "\n",
        "print(\"‚úÖ –°–æ–∑–¥–∞–Ω—ã –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\")\n",
        "print(f\"  1. average_score - —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞\")\n",
        "print(f\"  2. total_score - —Å—É–º–º–∞—Ä–Ω—ã–π –±–∞–ª–ª\")\n",
        "print(f\"  3. above_average - –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ (–±–∏–Ω–∞—Ä–Ω—ã–π)\")\n",
        "print(f\"  4. parent_education_level - —É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–æ–¥–∏—Ç–µ–ª–µ–π\")\n",
        "print(f\"  5. score_balance - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–æ–∫\")\n",
        "\n",
        "print(\"\\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ:\")\n",
        "print(f\"–†–∞–∑–º–µ—Ä: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "print(f\"–ö–æ–ª–æ–Ω–∫–∏: {df.columns.tolist()}\")\n",
        "\n",
        "print(\"\\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–æ–≤–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:\")\n",
        "print(df['average_score'].describe())\n",
        "\n",
        "# –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å EDA –∏ –º–æ–¥–µ–ª—å—é"
      ],
      "metadata": {
        "id": "J5ubB-6mQc9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "sns.histplot(df['average_score'], kde=True, bins=30)\n",
        "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–∏')\n",
        "plt.xlabel('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞')\n",
        "plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
        "\n",
        "# 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –ø–æ –ø—Ä–µ–¥–º–µ—Ç–∞–º\n",
        "plt.subplot(2, 3, 2)\n",
        "sns.boxplot(data=df[['math score', 'reading score', 'writing score']])\n",
        "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –ø–æ –ø—Ä–µ–¥–º–µ—Ç–∞–º')\n",
        "plt.ylabel('–û—Ü–µ–Ω–∫–∞')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# 3. –í–ª–∏—è–Ω–∏–µ –ø–æ–ª–∞ –Ω–∞ —É—Å–ø–µ–≤–∞–µ–º–æ—Å—Ç—å\n",
        "plt.subplot(2, 3, 3)\n",
        "sns.boxplot(x='gender', y='average_score', data=df)\n",
        "plt.title('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ –ø–æ–ª—É')\n",
        "plt.xlabel('–ü–æ–ª')\n",
        "plt.ylabel('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞')\n",
        "\n",
        "# 4. –í–ª–∏—è–Ω–∏–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —Ç–µ—Å—Ç—É\n",
        "plt.subplot(2, 3, 4)\n",
        "sns.boxplot(x='test preparation course', y='average_score', data=df)\n",
        "plt.title('–í–ª–∏—è–Ω–∏–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —Ç–µ—Å—Ç—É')\n",
        "plt.xlabel('–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Ç–µ—Å—Ç—É')\n",
        "plt.ylabel('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞')\n",
        "\n",
        "# 5. –í–ª–∏—è–Ω–∏–µ —É—Ä–æ–≤–Ω—è –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–æ–¥–∏—Ç–µ–ª–µ–π\n",
        "plt.subplot(2, 3, 5)\n",
        "sns.boxplot(x='parental level of education', y='average_score', data=df)\n",
        "plt.title('–í–ª–∏—è–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä–æ–¥–∏—Ç–µ–ª–µ–π')\n",
        "plt.xlabel('–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª–µ–π')\n",
        "plt.ylabel('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# 6. –í–ª–∏—è–Ω–∏–µ —Ç–∏–ø–∞ –æ–±–µ–¥–∞\n",
        "plt.subplot(2, 3, 6)\n",
        "sns.boxplot(x='lunch', y='average_score', data=df)\n",
        "plt.title('–í–ª–∏—è–Ω–∏–µ —Ç–∏–ø–∞ –æ–±–µ–¥–∞')\n",
        "plt.xlabel('–¢–∏–ø –æ–±–µ–¥–∞')\n",
        "plt.ylabel('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ix2lAqbtLGTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
        "numeric_cols = ['math score', 'reading score', 'writing score',\n",
        "                'average_score', 'total_score', 'parent_education_level', 'score_balance']\n",
        "\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RWly038xLHpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü–∞—Ä–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –æ—Ü–µ–Ω–∫–∞–º–∏\n",
        "sns.pairplot(df[['math score', 'reading score', 'writing score', 'gender']],\n",
        "             hue='gender', diag_kind='kde', height=2.5)\n",
        "plt.suptitle('–ü–∞—Ä–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ü–µ–Ω–æ–∫ –ø–æ –ø—Ä–µ–¥–º–µ—Ç–∞–º', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fqsanCbfLRKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "categorical_cols = ['gender', 'race/ethnicity', 'parental level of education',\n",
        "                    'lunch', 'test preparation course']\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º LabelEncoder –∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
        "label_encoders = {}\n",
        "df_encoded = df.copy()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
        "X = df_encoded.drop(['average_score', 'total_score', 'above_average'], axis=1)\n",
        "y = df_encoded['average_score']\n",
        "\n",
        "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train –∏ test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=df_encoded['above_average']\n",
        ")\n",
        "\n",
        "print(f\"–†–∞–∑–º–µ—Ä train: {X_train.shape}\")\n",
        "print(f\"–†–∞–∑–º–µ—Ä test: {X_test.shape}\")\n",
        "\n",
        "# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "scaler = StandardScaler()\n",
        "numeric_features = ['math score', 'reading score', 'writing score',\n",
        "                    'parent_education_level', 'score_balance']\n",
        "\n",
        "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
        "X_test[numeric_features] = scaler.transform(X_test[numeric_features])"
      ],
      "metadata": {
        "id": "VpQyK_8LLa1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "baseline_model = LinearRegression()\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "y_pred_baseline = baseline_model.predict(X_test)\n",
        "\n",
        "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
        "mse_baseline = mean_squared_error(y_test, y_pred_baseline)\n",
        "rmse_baseline = np.sqrt(mse_baseline)\n",
        "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
        "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"BASELINE MODEL (Linear Regression)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"R¬≤: {r2_baseline:.4f}\")\n",
        "print(f\"RMSE: {rmse_baseline:.4f}\")\n",
        "print(f\"MAE: {mae_baseline:.4f}\")\n",
        "print(f\"MSE: {mse_baseline:.4f}\")\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_baseline, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "plt.ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "plt.title('Baseline –º–æ–¥–µ–ª—å: —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xrs1nDj5LcCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Random Forest\n",
        "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è GridSearch\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# –ü–æ–∏—Å–∫ –ø–æ —Å–µ—Ç–∫–µ\n",
        "grid_search_rf = GridSearchCV(\n",
        "    rf_model, param_grid_rf, cv=5, scoring='r2',\n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"RANDOM FOREST REGRESSOR\")\n",
        "print(\"=\"*50)\n",
        "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search_rf.best_params_}\")\n",
        "print(f\"R¬≤: {r2_rf:.4f}\")\n",
        "print(f\"RMSE: {rmse_rf:.4f}\")\n",
        "\n",
        "# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': best_rf.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
        "plt.title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Random Forest)')\n",
        "plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xZA69w9oLxlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ XGBoost\n",
        "xgb_model = XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# –ü–æ–∏—Å–∫ –ø–æ —Å–µ—Ç–∫–µ\n",
        "grid_search_xgb = GridSearchCV(\n",
        "    xgb_model, param_grid_xgb, cv=5, scoring='r2',\n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "grid_search_xgb.fit(X_train, y_train)\n",
        "\n",
        "# –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "\n",
        "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"XGBOOST REGRESSOR\")\n",
        "print(\"=\"*50)\n",
        "print(f\"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search_xgb.best_params_}\")\n",
        "print(f\"R¬≤: {r2_xgb:.4f}\")\n",
        "print(f\"RMSE: {rmse_xgb:.4f}\")\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è XGBoost\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gain importance\n",
        "xgb.plot_importance(best_xgb, importance_type='weight', ax=ax1, max_num_features=10)\n",
        "ax1.set_title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ XGBoost (Weight)')\n",
        "\n",
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "ax2.scatter(y_test, y_pred_xgb, alpha=0.6, label='XGBoost')\n",
        "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "ax2.set_xlabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "ax2.set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "ax2.set_title('XGBoost: —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v2luOxGSLy0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# –ú–æ–¥–µ–ª—å Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
        "r2_gb = r2_score(y_test, y_pred_gb)\n",
        "rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"GRADIENT BOOSTING REGRESSOR\")\n",
        "print(\"=\"*50)\n",
        "print(f\"R¬≤: {r2_gb:.4f}\")\n",
        "print(f\"RMSE: {rmse_gb:.4f}\")"
      ],
      "metadata": {
        "id": "_36naMjUL484"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "comparison_df = pd.DataFrame({\n",
        "    '–ú–æ–¥–µ–ª—å': ['Linear Regression', 'Random Forest', 'XGBoost', 'Gradient Boosting'],\n",
        "    'R¬≤': [r2_baseline, r2_rf, r2_xgb, r2_gb],\n",
        "    'RMSE': [rmse_baseline, rmse_rf, rmse_xgb, rmse_gb],\n",
        "    'MAE': [mae_baseline,\n",
        "            mean_absolute_error(y_test, y_pred_rf),\n",
        "            mean_absolute_error(y_test, y_pred_xgb),\n",
        "            mean_absolute_error(y_test, y_pred_gb)]\n",
        "})\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"–°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ R¬≤\n",
        "axes[0].barh(comparison_df['–ú–æ–¥–µ–ª—å'], comparison_df['R¬≤'], color=['blue', 'green', 'orange', 'red'])\n",
        "axes[0].set_xlabel('R¬≤')\n",
        "axes[0].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–µ R¬≤')\n",
        "axes[0].axvline(x=comparison_df['R¬≤'].max(), color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ RMSE\n",
        "axes[1].barh(comparison_df['–ú–æ–¥–µ–ª—å'], comparison_df['RMSE'], color=['blue', 'green', 'orange', 'red'])\n",
        "axes[1].set_xlabel('RMSE')\n",
        "axes[1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –º–µ—Ç—Ä–∏–∫–µ RMSE')\n",
        "axes[1].axvline(x=comparison_df['RMSE'].min(), color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0N_qeBaMMA6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (XGBoost)\n",
        "residuals = y_test - y_pred_xgb\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤\n",
        "axes[0, 0].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].axvline(x=0, color='red', linestyle='--')\n",
        "axes[0, 0].set_xlabel('–û—Å—Ç–∞—Ç–∫–∏')\n",
        "axes[0, 0].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')\n",
        "axes[0, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ XGBoost')\n",
        "\n",
        "# 2. –û—Å—Ç–∞—Ç–∫–∏ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "axes[0, 1].scatter(y_pred_xgb, residuals, alpha=0.6)\n",
        "axes[0, 1].axhline(y=0, color='red', linestyle='--')\n",
        "axes[0, 1].set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "axes[0, 1].set_ylabel('–û—Å—Ç–∞—Ç–∫–∏')\n",
        "axes[0, 1].set_title('–û—Å—Ç–∞—Ç–∫–∏ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')\n",
        "\n",
        "# 3. Q-Q plot\n",
        "from scipy import stats\n",
        "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
        "axes[1, 0].set_title('Q-Q plot –æ—Å—Ç–∞—Ç–∫–æ–≤')\n",
        "\n",
        "# 4. –ù–∞–∏–±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏\n",
        "error_df = pd.DataFrame({\n",
        "    '–§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ': y_test.values,\n",
        "    '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ': y_pred_xgb,\n",
        "    '–û—à–∏–±–∫–∞': abs(residuals)\n",
        "}).sort_values('–û—à–∏–±–∫–∞', ascending=False)\n",
        "\n",
        "axes[1, 1].bar(range(10), error_df['–û—à–∏–±–∫–∞'].head(10))\n",
        "axes[1, 1].set_xlabel('–¢–æ–ø-10 –ø—Ä–∏–º–µ—Ä–æ–≤')\n",
        "axes[1, 1].set_ylabel('–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')\n",
        "axes[1, 1].set_title('–¢–æ–ø-10 –Ω–∞–∏–±–æ–ª—å—à–∏—Ö –æ—à–∏–±–æ–∫')\n",
        "axes[1, 1].set_xticks(range(10))\n",
        "axes[1, 1].set_xticklabels([f'#{i+1}' for i in range(10)], rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏\n",
        "print(\"=\"*60)\n",
        "print(\"–ê–ù–ê–õ–ò–ó –ù–ê–ò–ë–û–õ–¨–®–ò–• –û–®–ò–ë–û–ö\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n–¢–æ–ø-5 –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏:\")\n",
        "print(error_df.head().to_string())"
      ],
      "metadata": {
        "id": "NSKnkBYsMFZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "final_model = XGBRegressor(\n",
        "    colsample_bytree=1.0,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    n_estimators=300,\n",
        "    subsample=0.9,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "X_final = pd.concat([X_train, X_test])\n",
        "y_final = pd.concat([y_train, y_test])\n",
        "\n",
        "final_model.fit(X_final, y_final)\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å\n",
        "joblib.dump(final_model, 'student_performance_xgb_model.pkl')\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º scaler\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º label encoders\n",
        "with open('label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"–§–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨ –°–û–•–†–ê–ù–ï–ù–ê\")\n",
        "print(\"=\"*50)\n",
        "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã:\")\n",
        "print(\"1. student_performance_xgb_model.pkl - –º–æ–¥–µ–ª—å XGBoost\")\n",
        "print(\"2. scaler.pkl - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ç–æ—Ä\")\n",
        "print(\"3. label_encoders.pkl - –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π\")\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "def predict_student_performance(student_data):\n",
        "    \"\"\"\n",
        "    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Å–ø–µ–≤–∞–µ–º–æ—Å—Ç–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞\n",
        "    student_data: —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞\n",
        "    \"\"\"\n",
        "    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame\n",
        "    df_student = pd.DataFrame([student_data])\n",
        "\n",
        "    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "    for col in categorical_cols:\n",
        "        if col in label_encoders:\n",
        "            df_student[col] = label_encoders[col].transform([student_data[col]])[0]\n",
        "\n",
        "    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "    df_student['parent_education_level'] = df_student['parental level of education']\n",
        "    df_student['score_balance'] = abs(df_student['math score'] - df_student['reading score']) + \\\n",
        "                                   abs(df_student['math score'] - df_student['writing score']) + \\\n",
        "                                   abs(df_student['reading score'] - df_student['writing score'])\n",
        "\n",
        "    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
        "    if 'parental level of education' in df_student.columns:\n",
        "        df_student = df_student.drop('parental level of education', axis=1)\n",
        "\n",
        "    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
        "    df_student[numeric_features] = scaler.transform(df_student[numeric_features])\n",
        "\n",
        "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
        "    prediction = final_model.predict(df_student)[0]\n",
        "\n",
        "    return round(prediction, 2)\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "example_student = {\n",
        "    'gender': 'female',\n",
        "    'race/ethnicity': 'group C',\n",
        "    'parental level of education': \"bachelor's degree\",\n",
        "    'lunch': 'standard',\n",
        "    'test preparation course': 'completed',\n",
        "    'math score': 85,\n",
        "    'reading score': 90,\n",
        "    'writing score': 88\n",
        "}\n",
        "\n",
        "predicted_score = predict_student_performance(example_student)\n",
        "print(f\"\\n–ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞:\")\n",
        "print(f\"–î–∞–Ω–Ω—ã–µ: {example_student}\")\n",
        "print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {predicted_score}\")"
      ],
      "metadata": {
        "id": "Lf2BLWQ2MMGK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}